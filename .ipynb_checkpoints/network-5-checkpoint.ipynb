{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing classes and real network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    data : (10 000 x 3072)\n",
    "    labels : (10 000 x 1)\n",
    "    one_hot : (10 000 x 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    file = unpickle(\"data/cifar-10-batches-py/data_batch_1\")\n",
    "    labels = file[b'labels']\n",
    "    data = file[b'data']\n",
    "    no_classes = 10\n",
    "    N = len(labels)\n",
    "    \n",
    "    one_hot = np.zeros((N, no_classes))\n",
    "    one_hot[np.arange(N), labels] = 1\n",
    "    \n",
    "    labels = np.array(labels).reshape(-1,1)\n",
    "    \n",
    "    # normalize\n",
    "    mean = np.mean(data, axis=0, keepdims=True)\n",
    "    std = np.std(data, axis=0, keepdims=True)\n",
    "    \n",
    "    X = (data - mean) / std\n",
    "    return X, labels, one_hot, mean, std\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.where(x > 0, x, 0)\n",
    "\n",
    "def dReLU(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def plot_image(x, mean, std):\n",
    "    x = (x.T * std + mean).astype(int)\n",
    "    img = x.reshape(3,32,32)\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))\n",
    "\n",
    "def check_if_correct(y, p):\n",
    "    temp = np.argmax(y, axis=1) - np.argmax(p.T, axis=1)\n",
    "    correct_ones = np.where(temp == 0, 1, 0)\n",
    "    return np.sum(correct_ones)\n",
    "\n",
    "class Plotter:\n",
    "    def __init__(self, title):\n",
    "        self.title = title\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        \n",
    "    def add(self, epoch, cost):\n",
    "        self.y.append(cost)\n",
    "        self.x.append(epoch)\n",
    "    \n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(self.x, self.y)\n",
    "\n",
    "        ax.set(xlabel=\"epochs\", ylabel=\"cost\", title=self.title)\n",
    "        ax.grid()\n",
    "        # fig.savefig(\"{}.png\".format(self.title))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "\n",
    "def train():\n",
    "    plotter = Plotter(\"batch-norm-tester-\".format(time.time()))\n",
    "    data, labels, one_hots, mean, std = load_data()\n",
    "    data_size = data.shape[0]\n",
    "    lr = 0.05\n",
    "    w_decay = 0\n",
    "    no_hidden_1 = 50\n",
    "    no_hidden_2 = 30\n",
    "    output_nodes = 10\n",
    "    \n",
    "    W1 = np.random.rand(no_hidden_1, 3072) * 0.0001\n",
    "    W2 = np.random.rand(no_hidden_2, no_hidden_1) * 0.0001\n",
    "    W3 = np.random.rand(output_nodes, no_hidden_2) * 0.0001\n",
    "    \n",
    "    b1 = np.zeros((no_hidden_1, 1))\n",
    "    b2 = np.zeros((no_hidden_2, 1))\n",
    "    b3 = np.zeros((output_nodes, 1))\n",
    "        \n",
    "    gamma1 = np.random.rand(no_hidden_1, 1)\n",
    "    beta1 = np.zeros((no_hidden_1, 1))\n",
    "    \n",
    "    gamma2 = np.random.rand(no_hidden_2, 1)\n",
    "    beta2 = np.zeros((no_hidden_2, 1))\n",
    "    \n",
    "    batch_size = 100\n",
    "    iterations = data_size // batch_size\n",
    "    start_t = time.time()\n",
    "\n",
    "    for epoch in range(200):\n",
    "        avg_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        for idx in range(iterations):\n",
    "            start = batch_size * idx\n",
    "            end = batch_size * (idx + 1)\n",
    "\n",
    "            # get X and Y\n",
    "            X0 = data[start:end,:].T # 3072x100\n",
    "            one_hot = one_hots[start:end,:] # 100x10\n",
    "            \n",
    "            # Layer 1 with batch_norm\n",
    "            S1 = np.dot(W1, X0) + b1\n",
    "            mu_1 = np.sum(S1, axis=1).reshape(-1,1) / batch_size\n",
    "            var_1 = np.var(S1, axis=1)\n",
    "            \n",
    "            S1_hat = np.dot(np.diag( (var_1 + 1e-15) ** (-0.5) ), (S1 - mu_1)) # batchNorm\n",
    "            S1_t = gamma1 * S1_hat + beta1\n",
    "            \n",
    "            X1 = ReLU(S1_t)\n",
    "            \n",
    "            # Layer 2 with batch_norm\n",
    "            S2 = np.dot(W2, X1) + b2\n",
    "            mu_2 = np.sum(S2, axis=1).reshape(-1,1) / batch_size\n",
    "            var_2 = np.var(S2, axis=1)\n",
    "            \n",
    "            S2_hat = np.dot(np.diag( (var_2 + 1e-15) ** (-0.5) ), (S2 - mu_2))\n",
    "            S2_t = gamma2 * S2_hat + beta2\n",
    "            \n",
    "            X2 = ReLU(S2_t)\n",
    "            \n",
    "            # Layer 2 (last layer)\n",
    "            S3 = np.dot(W3, X2) + b3\n",
    "            X3 = softmax(S3) \n",
    "        \n",
    "            # LOG LOSS\n",
    "            L2 = np.sum(W1 ** 2) + np.sum(W2 ** 2) + np.sum(W3 ** 2)\n",
    "            loss = -np.sum(one_hot * np.log(1e-15 + X3.T)) + w_decay * L2\n",
    "\n",
    "            avg_loss += (loss / batch_size)\n",
    "            accuracy += check_if_correct(one_hot, X3)\n",
    "            \n",
    "            # print(\"forward done\")\n",
    "            # backward\n",
    "            \n",
    "            # dS2\n",
    "            G = X3 - one_hot.T # change X here\n",
    "            \n",
    "            dW3 = np.dot(G, X2.T) / batch_size\n",
    "            dW3 += 2 * w_decay * W3\n",
    "            db3 = np.sum(G, axis=1).reshape(-1,1) / batch_size\n",
    "            \n",
    "            # BatchNormBackPass Layer 2\n",
    "            G = np.dot(W3.T, G) * dReLU(X2) # dX2\n",
    "            dgamma2 = np.sum(G * S2_hat, axis=1, keepdims=True) / batch_size\n",
    "            dbeta2 = np.sum(G, axis=1, keepdims=True) / batch_size\n",
    "            \n",
    "            G = G * gamma2\n",
    "            sigma = var_2.reshape(-1,1) + 1e-15\n",
    "            sigma1 = sigma ** -0.5\n",
    "            sigma2 = sigma ** -1.5\n",
    "            \n",
    "            G1 = G * sigma1\n",
    "            G2 = G * sigma2\n",
    "            \n",
    "            D = S2 - mu_2\n",
    "            c = np.sum(G2 * D, axis=1, keepdims=True)\n",
    "            part1 = (1 / batch_size) * (G1 @ np.ones((batch_size, 1))) @ np.ones((1, batch_size))\n",
    "            part2 = (1 / batch_size) * D * (c @ np.ones((1, batch_size)))\n",
    "            \n",
    "            G = G1 - part1 - part2 # dS2\n",
    "            dW2 = np.dot(G, X1.T) / batch_size\n",
    "            dW2 += w_decay * 2 * W2\n",
    "            \n",
    "            db2 = np.sum(G, axis=1).reshape(-1,1) / batch_size\n",
    "        \n",
    "            \n",
    "            # BatchNormBackPass Layer 1\n",
    "            G = np.dot(W2.T, G)\n",
    "            G = G * dReLU(X1) # dX1\n",
    "            \n",
    "            dgamma1 = np.sum(G * S1_hat, axis=1, keepdims=True) / batch_size\n",
    "            dbeta1 = np.sum(G, axis=1, keepdims=True) / batch_size\n",
    "            \n",
    "            G = G * gamma1\n",
    "            \n",
    "            # == BatchNormBackPass ==\n",
    "            sigma = var_1.reshape(-1,1) + 1e-15\n",
    "            sigma1 = sigma ** -0.5\n",
    "            sigma2 = sigma ** -1.5\n",
    "            \n",
    "            G1 = G * sigma1\n",
    "            G2 = G * sigma2\n",
    "            \n",
    "            D = S1 - mu_1\n",
    "            c = np.sum(G2 * D,axis=1, keepdims=True) # 50x1 os√§ker\n",
    "            \n",
    "            part1 = (1 / batch_size) * (G1 @ np.ones((batch_size, 1))) @ np.ones((1, batch_size))\n",
    "            part2 = (1 / batch_size) * D * (c @ np.ones((1, batch_size)))\n",
    "            \n",
    "            G = G1 - part1 - part2\n",
    "            # ==========================\n",
    "            # G = dS1\n",
    "            \n",
    "            dW1 = np.dot(G, X0.T) / batch_size\n",
    "            dW1 += w_decay * 2 * W1\n",
    "            \n",
    "            db1 = np.sum(G, axis=1).reshape(-1,1) / batch_size\n",
    "            \n",
    "            # update\n",
    "            W1 = W1 - lr * dW1\n",
    "            b1 = b1 - lr * db1\n",
    "            W2 = W2 - lr * dW2\n",
    "            b2 = b2 - lr * db2\n",
    "            W3 = W3 - lr * dW3\n",
    "            b3 = b3 - lr * db3\n",
    "            \n",
    "            gamma1 = gamma1 - lr * dgamma1\n",
    "            beta1 = beta1 - lr * dbeta1\n",
    "            \n",
    "            gamma2 = gamma2 - lr * dgamma2\n",
    "            beta2 = beta2 - lr * dbeta2\n",
    "\n",
    "        avg_loss /= iterations\n",
    "        accuracy /= iterations\n",
    "    \n",
    "        if (epoch % 10 == 0):\n",
    "            plotter.add(epoch, avg_loss)\n",
    "            print(\"epoch: {} \\tloss: {:.3} \\tacc: {:.3}\".format(epoch, avg_loss, accuracy))\n",
    "\n",
    "    print(\"{:.3} s\".format(time.time() - start_t))\n",
    "    plotter.plot()\n",
    "    \n",
    "    # print(b1, \"\\n\", b2)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
